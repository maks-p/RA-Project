{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup: Resident Advisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:\n",
    "\n",
    "Resident Advisor is an events listing website for electronic music.\n",
    "\n",
    "Go to www.residentadvisor.net/events.  This is the url we'll be starting with for this lab.  For question 1, just use this url.  In the next two, you'll use country and region in the format: http://www.residentadvisor.net/country/region/ i.e. us/losangeles/.  Be sure to explore the web pages in both the browser and the HTML file.  You'll need both to really understand what's going on.\n",
    "\n",
    "1. Which venues are hosting events this week?\n",
    "2. Make a function which returns the events this week given region and country (this will take two arguments)\n",
    "    - return the event name, link, and list of artists\n",
    "    - function returns list of ['event name', 'www.linkaddress.com', ['artist1','artist2','artist3']]\n",
    "3. Create a function which returns the users attending \n",
    "4. Putting data into a dataframe\n",
    "5. Comparing data across dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Which venues are hosting events this week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from dateutil.rrule import rrule, DAILY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your solution output should look like: '101bklyn', '291 Hooper St', '99 Scott Ave','Alphaville', 'Analog Bkny'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.residentadvisor.net/events/us/newyork/day/2019-03-22\n"
     ]
    }
   ],
   "source": [
    "def find_dates(start_date, end_date):\n",
    "    a = date(2009, 5, 30)\n",
    "b = date(2009, 6, 9)\n",
    "\n",
    "for dt in rrule(DAILY, dtstart=a, until=b):\n",
    "    print dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "find_dates(\n",
    "\n",
    "\n",
    "def build_url(date):\n",
    "    host = 'https://www.residentadvisor.net/events/us/newyork/day/'\n",
    "    date = date\n",
    "    return host + date\n",
    "\n",
    "print(build_url('2019-03-22'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avant Gardner', 'TBA - Brooklyn', 'Knockdown Center', 'Analog Bkny', 'Elsewhere', '99 Scott Ave', 'Nowadays', 'Good Room', 'TBA - Brooklyn', 'TBA - New York', 'Rose Gold', 'Schimanski', 'Eris', 'Elsewhere', 'TBA Brooklyn', 'Hart bar', 'House Of Yes', 'Polygon BK', 'Bossa Nova Civic Club', 'Jupiter Disco', 'Le Bain', 'Nublu', 'Ceremony', 'Black Flamingo', 'Le Poisson Rouge', 'The Deep End', 'The Spirit Room, Buffalo/Rochester', 'Ms. Yoo', 'TBA - New York', 'Ignight']\n"
     ]
    }
   ],
   "source": [
    "def find_venue(url):\n",
    "    #pull correct url\n",
    "    r = requests.get('https://www.residentadvisor.net/events/us/newyork/day/2019-03-22')\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    #isolate HTML with event data\n",
    "    events = soup.find_all('article', class_='event-item')\n",
    "    \n",
    "    nightly_events = []\n",
    "    #loop through events to find element containing venue name\n",
    "    for event in events:\n",
    "        all_span = event.find_all('span')\n",
    "        for item in all_span:\n",
    "            if 'at' in item.get_text():\n",
    "                #append event to container after splitting and stripping\n",
    "                nightly_events.append((item.get_text().split('at')[1].strip()))\n",
    "            \n",
    "print(nightly_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Write a function to which returns the events this week given region and country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_events(country, region):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Housepitality:Della, Homero Espinosa, Jason Peters at F8 1192 Folsom',\n",
       " 'http://residentadvisor.net/events/1173172',\n",
       " ['Della', 'Homero Espinosa', 'Jason Peters']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you should be able to output something like this\n",
    "find_events('us','sanfrancisco')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Create a function which returns the numbers of users attending each event this week, given country and region.  Then plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_attending(country, region):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5, 4, 3, 49, 18, 10, 3, 2, 11]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you should be able to output something like this\n",
    "users_attending('us','newyork')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now use the function to make a histogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Put the data for all concerts in the US and UK into Pandas dataframes.\n",
    "Think about what columns to include - concert titles, region, venues, URLs, dates, etc. You'll want to have a dataframe per country.\n",
    "\n",
    "Also think about how to deal with inconsistent/NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (Bonus) - Compare the concert scenes of the two countries and find:\n",
    "1. The difference in the number of concert-hosting venues per country\n",
    "2. The number of concerts happening THIS SATURDAY in each country\n",
    "3. Are there any artists playing in both countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
